"""
å£°éŸ³å…‹éš†TTSæ¨¡å—
ä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡ŒéŸ³è‰²è½¬æ¢
"""

import os
import numpy as np
import soundfile as sf
import librosa
from typing import Optional


class VoiceCloneTTS:
    """
    å£°éŸ³å…‹éš†TTS
    é€šè¿‡éŸ³è‰²è½¬æ¢æŠ€æœ¯ï¼Œå°†åˆæˆè¯­éŸ³è½¬æ¢ä¸ºå‚è€ƒéŸ³é¢‘çš„éŸ³è‰²
    """

    def __init__(self, reference_audio_path: str = None):
        """
        åˆå§‹åŒ–

        å‚æ•°:
            reference_audio_path: å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        self.reference_audio_path = reference_audio_path or "/Users/haihui/dou/reference_voice.wav"
        self.reference_features = None

        if os.path.exists(self.reference_audio_path):
            self._load_reference()

    def _load_reference(self):
        """åŠ è½½å¹¶åˆ†æå‚è€ƒéŸ³é¢‘"""
        try:
            # åŠ è½½å‚è€ƒéŸ³é¢‘
            ref_audio, ref_sr = librosa.load(self.reference_audio_path, sr=22050)

            # æå–å‚è€ƒéŸ³é¢‘çš„ç‰¹å¾
            self.reference_features = {
                'pitch_mean': np.mean(librosa.yin(ref_audio, fmin=80, fmax=400)),
                'pitch_std': np.std(librosa.yin(ref_audio, fmin=80, fmax=400)),
                'energy_mean': np.mean(librosa.feature.rms(y=ref_audio)),
                'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=ref_audio, sr=ref_sr)),
            }

            print(f"âœ… å‚è€ƒéŸ³é¢‘åˆ†æå®Œæˆ")
            print(f"   - éŸ³é«˜å‡å€¼: {self.reference_features['pitch_mean']:.2f} Hz")
            print(f"   - é¢‘è°±é‡å¿ƒ: {self.reference_features['spectral_centroid']:.2f} Hz")

        except Exception as e:
            print(f"âš ï¸  å‚è€ƒéŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
            self.reference_features = None

    def convert_voice(
        self,
        source_audio_bytes: bytes,
        intensity: float = 0.7
    ) -> bytes:
        """
        è½¬æ¢éŸ³è‰²

        å‚æ•°:
            source_audio_bytes: æºéŸ³é¢‘æ•°æ®ï¼ˆMP3æ ¼å¼ï¼‰
            intensity: è½¬æ¢å¼ºåº¦ (0.0-1.0)ï¼Œè¶Šé«˜è¶Šæ¥è¿‘å‚è€ƒéŸ³è‰²

        è¿”å›:
            è½¬æ¢åçš„éŸ³é¢‘æ•°æ®ï¼ˆMP3æ ¼å¼ï¼‰
        """
        if not self.reference_features:
            print("âš ï¸  æœªåŠ è½½å‚è€ƒéŸ³é¢‘ï¼Œè¿”å›åŸéŸ³é¢‘")
            return source_audio_bytes

        try:
            import tempfile

            # ä¿å­˜æºéŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp_source:
                tmp_source.write(source_audio_bytes)
                source_path = tmp_source.name

            # åŠ è½½æºéŸ³é¢‘
            source_audio, source_sr = librosa.load(source_path, sr=22050)

            # åº”ç”¨éŸ³è‰²è½¬æ¢
            converted_audio = self._apply_voice_conversion(
                source_audio, source_sr, intensity
            )

            # ä¿å­˜è½¬æ¢åçš„éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_converted:
                converted_path = tmp_converted.name
                sf.write(converted_path, converted_audio, source_sr)

            # è½¬æ¢ä¸ºMP3
            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp_mp3:
                output_path = tmp_mp3.name

            import subprocess
            subprocess.run([
                'ffmpeg', '-i', converted_path,
                '-codec:a', 'libmp3lame', '-b:a', '128k',
                output_path, '-y'
            ], capture_output=True, check=True)

            # è¯»å–è½¬æ¢åçš„MP3
            with open(output_path, 'rb') as f:
                result_bytes = f.read()

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(source_path)
            os.unlink(converted_path)
            os.unlink(output_path)

            print(f"âœ… éŸ³è‰²è½¬æ¢å®Œæˆ (å¼ºåº¦: {intensity})")
            return result_bytes

        except Exception as e:
            print(f"âŒ éŸ³è‰²è½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return source_audio_bytes

    def _apply_voice_conversion(
        self,
        audio: np.ndarray,
        sr: int,
        intensity: float
    ) -> np.ndarray:
        """
        åº”ç”¨éŸ³è‰²è½¬æ¢ç®—æ³•

        ä½¿ç”¨ç®€åŒ–çš„éŸ³è‰²è½¬æ¢ï¼š
        1. è°ƒæ•´éŸ³é«˜ï¼ˆpitch shiftingï¼‰
        2. è°ƒæ•´éŸ³è‰²ç‰¹å¾ï¼ˆformant shiftingï¼‰
        3. è°ƒæ•´èƒ½é‡åŒ…ç»œ
        """
        if not self.reference_features:
            return audio

        # 1. åˆ†ææºéŸ³é¢‘çš„éŸ³é«˜
        source_pitch = librosa.yin(audio, fmin=80, fmax=400)
        source_pitch_mean = np.mean(source_pitch[source_pitch > 0])

        # 2. è®¡ç®—éŸ³é«˜åç§»
        if source_pitch_mean > 0 and self.reference_features['pitch_mean'] > 0:
            pitch_shift_semitones = 12 * np.log2(
                self.reference_features['pitch_mean'] / source_pitch_mean
            ) * intensity

            # åº”ç”¨éŸ³é«˜åç§»
            audio = librosa.effects.pitch_shift(
                audio, sr=sr, n_steps=pitch_shift_semitones
            )

        # 3. è°ƒæ•´æ—¶åŸŸç‰¹å¾ï¼ˆå¯é€‰ï¼šè°ƒæ•´è¯­é€Ÿï¼‰
        # è¿™é‡Œä¿æŒè¯­é€Ÿä¸å˜ï¼Œåªè°ƒæ•´éŸ³è‰²

        # 4. è°ƒæ•´èƒ½é‡åŒ…ç»œ
        source_energy = librosa.feature.rms(y=audio)
        if self.reference_features['energy_mean'] > 0:
            energy_ratio = self.reference_features['energy_mean'] / np.mean(source_energy)
            # é™åˆ¶èƒ½é‡è°ƒæ•´èŒƒå›´ï¼Œé¿å…è¿‡åº¦
            energy_ratio = np.clip(energy_ratio, 0.7, 1.3)
            audio = audio * (1 + (energy_ratio - 1) * intensity)

        # å½’ä¸€åŒ–ï¼Œé˜²æ­¢çˆ†éŸ³
        audio = librosa.util.normalize(audio)

        return audio


async def text_to_speech_custom_voice(
    text: str,
    intensity: float = 0.7,
    base_voice: str = '502004',  # ä½¿ç”¨è…¾è®¯äº‘çš„æ™ºå°æ»¡ä½œä¸ºåŸºç¡€éŸ³è‰²
    speed: float = 1.5,
    volume: float = 10
) -> bytes:
    """
    ä½¿ç”¨è‡ªå®šä¹‰éŸ³è‰²åˆæˆè¯­éŸ³

    æµç¨‹:
    1. ä½¿ç”¨è…¾è®¯äº‘TTSç”ŸæˆåŸºç¡€è¯­éŸ³
    2. åº”ç”¨éŸ³è‰²è½¬æ¢ï¼Œä½¿å…¶æ¥è¿‘å‚è€ƒéŸ³é¢‘

    å‚æ•°:
        text: æ–‡æœ¬å†…å®¹
        intensity: éŸ³è‰²è½¬æ¢å¼ºåº¦ (0.0-1.0)
        base_voice: åŸºç¡€éŸ³è‰²
        speed: è¯­é€Ÿ
        volume: éŸ³é‡

    è¿”å›:
        MP3éŸ³é¢‘æ•°æ®
    """
    from tencent_tts import text_to_speech_tencent

    # 1. ä½¿ç”¨è…¾è®¯äº‘TTSç”ŸæˆåŸºç¡€éŸ³é¢‘
    print(f"ğŸ”Š ä½¿ç”¨åŸºç¡€éŸ³è‰² {base_voice} åˆæˆè¯­éŸ³...")
    base_audio = await text_to_speech_tencent(
        text=text,
        voice=base_voice,
        speed=speed,
        volume=volume
    )

    # 2. åº”ç”¨éŸ³è‰²è½¬æ¢
    print(f"ğŸ¨ åº”ç”¨è‡ªå®šä¹‰éŸ³è‰²è½¬æ¢ (å¼ºåº¦: {intensity})...")
    voice_clone = VoiceCloneTTS()
    custom_audio = voice_clone.convert_voice(base_audio, intensity=intensity)

    return custom_audio


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    import asyncio

    async def test():
        # æµ‹è¯•æ–‡æœ¬
        test_text = "åå­£ä¹°è¡£æœçœŸçš„èƒ½çœå¥½å‡ ç™¾å•Šï¼ä»Šå¤©ç»™å¤§å®¶å¸¦æ¥ä¸€æ¬¾è¶…å€¼çš„ç¾½ç»’é©¬ç”²ã€‚"

        print("æ­£åœ¨åˆæˆè‡ªå®šä¹‰éŸ³è‰²è¯­éŸ³...")
        audio_data = await text_to_speech_custom_voice(
            text=test_text,
            intensity=0.7
        )

        # ä¿å­˜éŸ³é¢‘
        with open('test_custom_voice.mp3', 'wb') as f:
            f.write(audio_data)

        print(f"âœ… è‡ªå®šä¹‰éŸ³è‰²åˆæˆå®Œæˆï¼Œå·²ä¿å­˜åˆ° test_custom_voice.mp3")

    asyncio.run(test())
